{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_classifier import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Data\n",
      "(24, 21, 600)\n",
      "(600, 24, 21)\n",
      "(200, 3, 504)\n",
      "---------- Data\n",
      "---------- Pose\n",
      "(48, 40, 13, 68)\n",
      "(68, 13, 48, 40)\n",
      "---------- Pose\n",
      "---------- Illum\n",
      "(1920, 21, 68)\n",
      "(68, 21, 1920)\n",
      "---------- Illum\n"
     ]
    }
   ],
   "source": [
    "def GetAllData():\n",
    "    data_all = {}\n",
    "    # data.mat\n",
    "    # 200 subjects\n",
    "    # 3 faces per subject\n",
    "    # size: 24 x 21\n",
    "    print('-'*10,'Data')\n",
    "    data = loadmat('data.mat')\n",
    "    data = data['face']\n",
    "    print(data.shape)\n",
    "    # LAbel each 200 classes with their index and set as label\n",
    "    labels_data = []\n",
    "    for i in range(data.shape[2]):\n",
    "        labels_data.append('lbl'+str(i+1))\n",
    "\n",
    "    data = np.moveaxis(data, -1, 0)\n",
    "    print(data.shape)\n",
    "    # Separate 3 faces for the 200 subjects\n",
    "    data = data.reshape(200,3,(24*21))\n",
    "    print(data.shape)\n",
    "    data_all['data'] = (data,labels_data)\n",
    "    print('-'*10,'Data')\n",
    "\n",
    "    print('-'*10,'Pose')\n",
    "    # 68 subjects\n",
    "    # 13 images per subject (13 different poses)\n",
    "    # size: 48 x 40\n",
    "    pose = loadmat('pose.mat')\n",
    "    pose = pose['pose']\n",
    "    labels_pose = []\n",
    "    for i in range(pose.shape[3]):\n",
    "        labels_pose.append('lbl'+str(i+1))\n",
    "    print(pose.shape)\n",
    "    pose = np.moveaxis(np.moveaxis(pose,-1,0),-1,1)\n",
    "    print(pose.shape)\n",
    "    data_all['pose'] = (pose,labels_pose)\n",
    "    print('-'*10,'Pose')\n",
    "\n",
    "    print('-'*10,'Illum')\n",
    "    # 68 subjects\n",
    "    # 21 images per subject (21 different illuminations)\n",
    "    # size: 48x40\n",
    "    illum = loadmat('illumination.mat')\n",
    "    illum = illum['illum']\n",
    "    labels_illum = []\n",
    "    print(illum.shape)\n",
    "    for i in range(illum.shape[2]):\n",
    "        labels_illum.append('lbl'+str(i+1))\n",
    "    illum = np.moveaxis(np.moveaxis(illum,-1,0),-1,1)\n",
    "    print(illum.shape)\n",
    "    data_all['illum'] = (illum,labels_illum)\n",
    "    print('-'*10,'Illum')\n",
    "\n",
    "    return data_all\n",
    "\n",
    "\n",
    "data_all = GetAllData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = {}\n",
    "y_train = {}\n",
    "#  [data,pose,illum]\n",
    "n = [20,20,45]\n",
    "m = [2,7,16]\n",
    "#\n",
    "c=0\n",
    "train_test_all = {}  # Format-> Dataset: (TrainX, TrainY, TestX, TestY)\n",
    "# Can test the effect of expressions, illumination variations. \n",
    "# Here we test the effect of illumination for data.mat\n",
    "for k in data_all:\n",
    "    train_datax = data_all[k][0][:,:m[c],:]\n",
    "    train_datay = data_all[k][1]\n",
    "    samples = range(data_all[k][0].shape[0])\n",
    "    # ndarray generated random samples for test data\n",
    "    rand_indexs = np.array(np.random.choice(samples, n[c], replace = False))\n",
    "    test_datax = data_all[k][0][rand_indexs,m[c],:]\n",
    "    test_datay = np.array(data_all[k][1])[rand_indexs]\n",
    "    train_test_all[k] = (train_datax,train_datay,test_datax,test_datay)\n",
    "    c+=1\n",
    "    pass\n",
    "\n",
    "#train_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2, 504)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_all['data'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run without dimensionality reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Add noise = 0.1 to avoid singularity whne calculating covariance.\n",
    "classifier = BayesClassifier(0.1)\n",
    "predicted_data1,predicted_data2 = classifier.classify(train_test_all['data'][0],train_test_all['data'][2])\n",
    "print(accuracy_score(predicted_data2,train_test_all['data'][3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Add noise = 0.1 to avoid singularity whne calculating covariance.\n",
    "classifier = BayesClassifier(0.1)\n",
    "train_x = train_test_all['pose'][0]\n",
    "test_x = train_test_all['pose'][2]\n",
    "train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2]*train_x.shape[3])\n",
    "test_x = test_x.reshape(test_x.shape[0],test_x.shape[1]*test_x.shape[2])\n",
    "predicted_pose1,predicted_pose2 = classifier.classify(train_x,test_x)\n",
    "print(accuracy_score(predicted_pose2,train_test_all['pose'][3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Illumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Add noise = 0.1 to avoid singularity whne calculating covariance.\n",
    "classifier = BayesClassifier(0.1)\n",
    "predicted_illum1,predicted_illum2 = classifier.classify(train_test_all['illum'][0],train_test_all['illum'][2])\n",
    "print(accuracy_score(predicted_illum2,train_test_all['illum'][3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:  10  Accuraccy:  0.2\n",
      "Component:  30  Accuraccy:  0.4666666666666667\n",
      "Component:  70  Accuraccy:  0.6\n",
      "Component:  200  Accuraccy:  0.7333333333333333\n",
      "Component:  250  Accuraccy:  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Try with different number of components\n",
    "num_comp = [10,30,70,200,250]\n",
    "train_x = train_test_all['data'][0]\n",
    "test_x = train_test_all['data'][2]\n",
    "# Resize to 2D:\n",
    "acc_bayes_pca_data = []\n",
    "train_x = train_x.reshape(train_x.shape[0]*train_x.shape[1],train_x.shape[2])\n",
    "for num in num_comp:\n",
    "    pca = PCA(num)\n",
    "    pca.fit(train_x)\n",
    "    train_x_dash = pca.transform(train_x)\n",
    "    # pca = PCA(num)\n",
    "    # pca.fit(test_x)\n",
    "    test_x_dash = pca.transform(test_x)\n",
    "    # print(train_x_dash.shape)\n",
    "    # print(test_x_dash.shape)\n",
    "    train_x_dash = train_x_dash.reshape(200,2,num)\n",
    "\n",
    "    classifier = BayesClassifier(0.75)\n",
    "    predicted_data_pca1,predicted_data_pca2 = classifier.classify(train_x_dash,test_x_dash)\n",
    "    acc = accuracy_score(predicted_data_pca2,train_test_all['data'][3])\n",
    "    print('Component: ',num,' Accuraccy: ',acc)\n",
    "    acc_bayes_pca_data.append(acc)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 :\t 0.7\n",
      "30 :\t 1.0\n",
      "70 :\t 1.0\n",
      "200 :\t 1.0\n",
      "250 :\t 1.0\n"
     ]
    }
   ],
   "source": [
    "# Try with different number of components\n",
    "num_comp = [10,30,70,200,250]\n",
    "train_x = train_test_all['pose'][0]\n",
    "test_x = train_test_all['pose'][2]\n",
    "# Resize to 2D:\n",
    "train_x = train_x.reshape(train_x.shape[0]*train_x.shape[1],train_x.shape[2]*train_x.shape[3])\n",
    "test_x = test_x.reshape(test_x.shape[0],test_x.shape[1]*test_x.shape[2])\n",
    "acc_bayes_pca_pose = []\n",
    "for num in num_comp:\n",
    "    pca = PCA(num)\n",
    "    pca.fit(train_x)\n",
    "    train_x_dash = pca.transform(train_x)\n",
    "    test_x_dash = pca.transform(test_x)\n",
    "    # print(train_x_dash.shape)\n",
    "    # print(test_x_dash.shape)\n",
    "    train_x_dash = train_x_dash.reshape(68,7,num)\n",
    "\n",
    "    classifier = BayesClassifier(0.1)\n",
    "    predicted_pose_pca1,predicted_pose_pca2 = classifier.classify(train_x_dash,test_x_dash)\n",
    "    acc = accuracy_score(predicted_pose_pca2,train_test_all['pose'][3])\n",
    "    print(num,':\\t',acc)\n",
    "    acc_bayes_pca_pose.append(acc)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Illum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222222222222222\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Try with different number of components\n",
    "num_comp = [10,30,70,200,250]\n",
    "train_x = train_test_all['illum'][0]\n",
    "test_x = train_test_all['illum'][2]\n",
    "# Resize to 2D:\n",
    "train_x = train_x.reshape(train_x.shape[0]*train_x.shape[1],train_x.shape[2])\n",
    "for num in num_comp:\n",
    "    pca = PCA(num)\n",
    "    pca.fit(train_x)\n",
    "    train_x_dash = pca.transform(train_x)\n",
    "    test_x_dash = pca.transform(test_x)\n",
    "    # print(train_x_dash.shape)\n",
    "    # print(test_x_dash.shape)\n",
    "    train_x_dash = train_x_dash.reshape(68,16,num)\n",
    "\n",
    "    classifier = BayesClassifier(0.15)\n",
    "    predicted_illum_pca1,predicted_illum_pca2 = classifier.classify(train_x_dash,test_x_dash)\n",
    "    print(accuracy_score(predicted_illum_pca2,train_test_all['illum'][3]))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Discriminant Analysis (MDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.4666666666666667\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "train_x = train_test_all['data'][0]\n",
    "test_x = train_test_all['data'][2]\n",
    "num_newdim = [10,30,70,200,250]\n",
    "for n_dim in num_newdim:\n",
    "    mda_data = MDA(0.9,train_x,test_x,n_dim)\n",
    "    mda_data.get_matA()\n",
    "    train_x_dash = mda_data.transform(train_x)\n",
    "    test_x_dash = mda_data.transform(test_x)\n",
    "\n",
    "    # Add noise = 0.1 to avoid singularity whne calculating covariance.\n",
    "    classifier = BayesClassifier(0.95)\n",
    "    predicted_data_mda1,predicted_data_mda2 = classifier.classify(train_x_dash,test_x_dash)\n",
    "    print(accuracy_score(predicted_data_mda2,train_test_all['data'][3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "train_x = train_test_all['pose'][0]\n",
    "test_x = train_test_all['pose'][2]\n",
    "train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2]*train_x.shape[3])\n",
    "test_x = test_x.reshape(test_x.shape[0],test_x.shape[1]*test_x.shape[2])\n",
    "num_newdim = [10,30,70,200,250]\n",
    "for n_dim in num_newdim:\n",
    "    mda_pose = MDA(0.5,train_x,test_x,n_dim)\n",
    "    mda_pose.get_matA()\n",
    "    train_x_dash = mda_pose.transform(train_x)\n",
    "    test_x_dash = mda_pose.transform(test_x)\n",
    "    # Add noise = 0.8 to avoid singularity whne calculating covariance.\n",
    "    classifier = BayesClassifier(0.8)\n",
    "    predicted_pose_mda1,predicted_pose_mda2 = classifier.classify(train_x_dash,test_x_dash)\n",
    "    print(accuracy_score(predicted_pose_mda2,train_test_all['pose'][3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Illumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t: 0.8\n",
      "30 \t: 1.0\n",
      "70 \t: 1.0\n",
      "200 \t: 1.0\n",
      "250 \t: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_x = train_test_all['illum'][0]\n",
    "test_x = train_test_all['illum'][2]\n",
    "acc_bayes_MDA_illum = []\n",
    "num_newdim = [10,30,70,200,250]\n",
    "for n_dim in num_newdim:\n",
    "    mda_illum = MDA(0.1,train_x,test_x,n_dim)\n",
    "    mda_illum.get_matA()\n",
    "    train_x_dash = mda_illum.transform(train_x)\n",
    "    test_x_dash = mda_illum.transform(test_x)\n",
    "\n",
    "    classifier = BayesClassifier(0.75)\n",
    "    predicted_illum_mda1,predicted_illum_mda2 = classifier.classify(train_x_dash,test_x_dash)\n",
    "    acc = accuracy_score(predicted_illum_mda2,train_test_all['illum'][3])\n",
    "    print(n_dim,'\\t:',acc)\n",
    "    acc_bayes_MDA_illum.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0a79c76574919354e3ac5f8de62c0c23dfecd089a514de40db9df7886111055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
